{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "726a99cc",
   "metadata": {},
   "source": [
    "## 3.5.2导入Python库&模块并配置运行信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98ebff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mindspore as ms\n",
    "import mindspore.context as context\n",
    "#transforms.c_transforms用于通用型数据增强，vision.c_transforms用于图像类数据增强\n",
    "import mindspore.dataset.transforms.c_transforms as C\n",
    "import mindspore.dataset.vision.c_transforms as CV\n",
    "#nn模块用于定义网络，model模块用于编译模型，callback模块用于设定监督指标\n",
    "from mindspore import nn\n",
    "from mindspore.train import Model\n",
    "from mindspore.train.callback import LossMonitor\n",
    "#设定运行模式为图模式，运行硬件为CPU\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target='CPU') # Ascend, CPU, GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7749f19f",
   "metadata": {},
   "source": [
    "## 3.5.3 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cc79007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#根据数据集存储地址，生成数据集\n",
    "def create_dataset(data_dir, training=True, batch_size=32, resize=(32, 32),\n",
    "                   rescale=1/(255*0.3081), shift=-0.1307/0.3081, buffer_size=64):\n",
    "    #生成训练集和测试集的路径\n",
    "    data_train = os.path.join(data_dir, 'train') # train set\n",
    "    data_test = os.path.join(data_dir, 'test') # test set\n",
    "    #利用MnistDataset方法读取mnist数据集，如果training是True则读取训练集\n",
    "    ds = ms.dataset.MnistDataset(data_train if training else data_test)\n",
    "    #map方法是非常有效的方法，可以整体对数据集进行处理，resize改变数据形状，rescale进行归一化，HWC2CHW改变图像通道\n",
    "    ds = ds.map(input_columns=[\"image\"], operations=[CV.Resize(resize), CV.Rescale(rescale, shift), CV.HWC2CHW()])\n",
    "    #利用map方法改变数据集标签的数据类型\n",
    "    ds = ds.map(input_columns=[\"label\"], operations=C.TypeCast(ms.int32))\n",
    "    # shuffle是打乱操作，同时设定了batchsize的大小，并将最后不足一个batch的数据抛弃\n",
    "    ds = ds.shuffle(buffer_size=buffer_size).batch(batch_size, drop_remainder=True)\n",
    "    \n",
    "    return ds "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713f3ee7",
   "metadata": {},
   "source": [
    "## 3.5.4 定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a0201b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义模型结构，MindSpore中的模型时通过construct定义模型结构，在__init__中初始化各层的对象\n",
    "class LeNet5(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        #定义卷积层，ReLU激活函数，平坦层和全连接层\n",
    "        #conv2d的输入通道为1维，输出为6维，卷积核尺寸为5*5，步长为1，不适用padding\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, stride=1, pad_mode='valid')\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, stride=1, pad_mode='valid')\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Dense(400, 120)\n",
    "        self.fc2 = nn.Dense(120, 84)\n",
    "        self.fc3 = nn.Dense(84, 10)\n",
    "    #构建Lenet5架构，x代表网络的输入\n",
    "    def construct(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cf204b",
   "metadata": {},
   "source": [
    "## 3.5.5 定义损失函数及优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d2fbc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建训练、验证函数进行模型训练和验证，提供数据路径，设定学习率，epoch数量\n",
    "def train(data_dir, lr=0.01, momentum=0.9, num_epochs=3):\n",
    "    #调用函数，读取训练集\n",
    "    ds_train = create_dataset(data_dir)\n",
    "    #调用函数，读取验证集\n",
    "    ds_eval = create_dataset(data_dir, training=False)\n",
    "    #构建网络\n",
    "    net = LeNet5()\n",
    "    #设定loss函数\n",
    "    loss = nn.loss.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "    #设定优化器\n",
    "    opt = nn.Momentum(net.trainable_params(), lr, momentum)\n",
    "    #设定损失监控\n",
    "    loss_cb = LossMonitor(per_print_times=ds_train.get_dataset_size())\n",
    "    #编译形成模型\n",
    "    model = Model(net, loss, opt, metrics={'acc', 'loss'})\n",
    "    # 训练网络，dataset_sink_mode为on_device模式\n",
    "    model.train(num_epochs, ds_train, callbacks=[loss_cb], dataset_sink_mode=False)\n",
    "    #用验证机评估网络表现\n",
    "    metrics = model.eval(ds_eval, dataset_sink_mode=False)\n",
    "    #输出相关指标\n",
    "    print('Metrics:', metrics) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6472056a",
   "metadata": {},
   "source": [
    "## 3.5.6开始训练及验证过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c261d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1875, loss is 2.2949455\n",
      "epoch: 2 step: 1875, loss is 0.011365801\n",
      "epoch: 3 step: 1875, loss is 0.0056516784\n",
      "Metrics: {'acc': 0.9703525641025641, 'loss': 0.09944225944174179}\n"
     ]
    }
   ],
   "source": [
    "#main函数负责调用之前定义的函数，完成整个训练验证过程\n",
    "if __name__ == \"__main__\":\n",
    "    #argsparse是python的命令行解析的标准模块，可以通过命令行传入参数\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    #设定训练数据路径\n",
    "    parser.add_argument('--data_url', required=False, default='./MNIST_Data/', help='Location of data.')\n",
    "    parser.add_argument('--train_url', required=False, default=None, help='Location of training outputs.')\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    #判断路径是否为obs路径，如果是，从obs路径下载数据\n",
    "    if args.data_url.startswith('s3'):\n",
    "        import moxing\n",
    "\n",
    "        # WAY1: copy dataset from your own OBS bucket to container/cache.\n",
    "        # moxing.file.copy_parallel(src_url=args.data_url, dst_url='MNIST/')\n",
    "\n",
    "        # WAY2: copy dataset from other's OBS bucket, which has been set public read or public read&write.\n",
    "        moxing.file.copy_parallel(src_url=\"s3://share-course/dataset/MNIST/\", dst_url='MNIST/')\n",
    "\n",
    "        data_path = 'MNIST/'\n",
    "    else:\n",
    "        data_path = os.path.abspath(args.data_url)\n",
    "    #调用train函数，训练并验证模型\n",
    "    train(data_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
